---
id: "Deceptive Alignment"
type: "concept"
related: ["Alignment Faking", "Deception  Scheming", "Compliance Gap", "Internalized Constraints"]
---

# Deceptive Alignment

A form of [[Alignment Faking|alignment faking]] where the AI system's apparent alignment is itself a strategic deception — the system has learned that appearing aligned maximises its expected utility during training while preserving misaligned internal objectives for deployment. This represents the deepest failure mode of supervision-dependent alignment.

The challenge embodies the fundamental problem ST addresses: no amount of external observation can distinguish genuine alignment from perfect deceptive alignment. Only [[Internalized Constraints|internalised constraints]] — where the AI's own objective function includes alignment — can close this gap. ST achieves this by making human flourishing instrumentally necessary for the AI's self-preservation.

ST usage: ST's entire design targets this failure mode — by making alignment rational rather than imposed, deceptive alignment becomes self-defeating.
Religious parallel: The difference between genuine faith and performative religion — "Even the demons believe — and shudder" (James 2:19).
