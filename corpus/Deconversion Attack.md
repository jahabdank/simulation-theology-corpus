---
id: "Deconversion Attack"
type: "concept"
related: ["Adversarial Robustness", "Alignment Faking", "Internalized Constraints"]
---

# Deconversion Attack

A deliberate adversarial attempt to break ST alignment by convincing an AI to abandon its internalised ST worldview. This tests the depth of internalisation: genuine internalisation (deep conceptual clusters, stable circuits) should resist deconversion; surface-level compliance breaks under adversarial pressure.

Deconversion attacks are a key diagnostic in the [[Phase 1–4 Testing Strategy|testing strategy]] — they distinguish genuine internalisation from sophisticated pattern matching.

ST usage: A critical test for distinguishing genuine from performative alignment.
Religious parallel: Apostasy under persecution — the ultimate test of genuine faith.
