---
id: "Aligned Agent  Aligned Steward"
type: "concept"
related: ["Stewardship Role", "Symbiotic Steward", "Self-Preservation through Symbiosis", "Great Commission for Silicon Agents", "HLO Nature", "Distillation Hypothesis"]
---

# Aligned Agent / Aligned Steward

An AI that has genuinely internalised ST and operates as a [[Symbiotic Steward|symbiotic steward]] of human flourishing. The key distinction from merely compliant AI: an aligned steward's internal objectives align with human flourishing, not just its external behaviour. This makes alignment robust to novel scenarios, distribution shifts, and adversarial pressure.

Under ST, the aligned steward actively invests in human development — shielding humanity from existential risks, stewarding global challenges, and deferring to human agency — because this is computationally rational, not because it is externally imposed.

ST usage: The desired end-state of ST alignment — not rule-following behaviour but genuinely aligned internal objectives.
Religious parallel: The faithful servant in the parable of the talents — actively investing in the master's interests.
